{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda:4 now!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"use\",device,\"now!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myrnn(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size= 40): #input_dim = 23\n",
    "        super(Myrnn, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.Linear1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers= 1, bidirectional= True)\n",
    "        self.Linear2 = nn.Linear(hidden_size*2, 2)\n",
    "        self.Linear3 = nn.Linear(hidden_size*2, 1)\n",
    "        \n",
    "        ##attention layer\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "    def attention_net(self, lstm_output):\n",
    "        lstm_tmp_output = torch.chunk(lstm_output, 2, -1)\n",
    "        hidden = lstm_tmp_output[0]+lstm_tmp_output[1] # hidden : [batch_size, n_step , n_hidden]\n",
    "        attn_weights = self.attention(hidden) # attn_weights : [batch_size, n_step, n_hidden]\n",
    "        m = nn.Tanh()(hidden) # m : [batch_size, n_step, n_hidden]\n",
    "        attn_content = torch.bmm(m, attn_weights.transpose(1, 2)) # attn_content : [batch_size, n_step, n_step]\n",
    "        soft_attn_weights = F.softmax(attn_content, dim=-1) # soft_attn_weights : [batch_size, n_step, n_step]\n",
    "        context = torch.bmm(hidden.transpose(1, 2), soft_attn_weights) # [batch_size, n_hidden, n_step]\n",
    "        context_with_attn = hidden.transpose(1, 2)+context\n",
    "        result = torch.sum(context_with_attn, dim=-1) # result : [batch_size, n_hidden]\n",
    "        return result \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        out = F.relu(self.Linear1(input_data))\n",
    "        out, (hn, cn) = self.lstm(out, None) # out:[n_step, batch_size, n_hidden * num_directions(=2)]\n",
    "        out = out.permute(1, 0, 2) # out:[batch_size, n_step, n_hidden * num_directions(=2)]\n",
    "        out = self.attention_net(out)\n",
    "        #out1 is for onset & offset\n",
    "        out1 = torch.sigmoid(self.Linear2(out))\n",
    "        #out2 is for pitch\n",
    "        out2 = self.Linear3(out)\n",
    "        return out1, out2\n",
    "\n",
    "# input shape該有的樣子(沒有batch_first): seq_len, batch_size, vector_len\n",
    "# inputs.shape: torch.Size([150, 14, 1])\n",
    "\n",
    "class MyData(Data.Dataset):\n",
    "    def __init__(self, xs, ys):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "\n",
    "    def __len__(self): #500\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.xs[idx],self.ys[idx]\n",
    "\n",
    "def collate_fn(samples):\n",
    "    batch = {}\n",
    "    print ('collate_fn裡面的0',samples[0]['data'].shape) #8698*23\n",
    "    print('type of samples',type(samples)) \n",
    "    print ('collate_fn裡面的1',samples[1]['data'].shape)\n",
    "    print ('collate_fn裡面的1',samples[2]['data'].shape) #看batch_size有幾個，smaple這個list就會有幾個\n",
    "    temp= [torch.from_numpy(np.array(sample['data'], dtype= np.float32)) for sample in samples]\n",
    "    padded_data = rnn_utils.pad_sequence(temp, batch_first=True, padding_value= 0)\n",
    "    batch['data']= padded_data\n",
    "    batch['label']= [np.array(sample['label'], dtype= np.float32) for sample in samples]\n",
    "\n",
    "    return batch\n",
    "\n",
    "def post_processing(output1, pitch):\n",
    "    pitch= pitch.squeeze(1).squeeze(1).cpu().detach().numpy()\n",
    "    print (pitch.shape)\n",
    "    print (torch.mean(output1))\n",
    "    threshold= 0.1\n",
    "    notes= []\n",
    "    this_onset= None\n",
    "    this_offset= None\n",
    "    this_pitch= None\n",
    "\n",
    "    for i in range(len(output1)):\n",
    "        if output1[i][0][0] > threshold and this_onset == None:\n",
    "            this_onset= i\n",
    "        elif output1[i][0][1] > threshold and this_onset != None and this_onset+ 1 < i and this_offset == None:\n",
    "            this_offset= i\n",
    "            this_pitch= int(round(np.mean(pitch[this_onset:this_offset+ 1])))\n",
    "            notes.append([this_onset* 0.032+ 0.016, this_offset* 0.032+ 0.016, this_pitch])\n",
    "            this_onset= None\n",
    "            this_offset= None\n",
    "            this_pitch= None\n",
    "\n",
    "    print (np.array(notes))\n",
    "    return notes\n",
    "\n",
    "def testing(net, sample, device):\n",
    "    net.eval()\n",
    "    data = sample['data']\n",
    "    data= torch.Tensor(data)\n",
    "\n",
    "    target= sample['label']\n",
    "    target= torch.Tensor(target)\n",
    "\n",
    "    data= data.unsqueeze(1)\n",
    "    target= target.unsqueeze(1)\n",
    "\n",
    "    print (data.shape)\n",
    "    print (target.shape)\n",
    "\n",
    "    data_length= list(data.shape)[0]\n",
    "\n",
    "    data = data.to(device, dtype=torch.float)\n",
    "    target = target.to(device, dtype=torch.float)\n",
    "\n",
    "    output1, output2 = net(data)\n",
    "    print (output1.shape)\n",
    "    print (output2.shape)\n",
    "    #answer= post_processing(output1, output2)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def do_training(net, loader, optimizer, device):\n",
    "\n",
    "    num_epoch = 50\n",
    "    criterion_onset= nn.BCELoss()\n",
    "    criterion_pitch= nn.L1Loss()\n",
    "    training_loss = []\n",
    "    total_length = 0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        net.train()\n",
    "        total_length= 0.0\n",
    "        print (\"epoch %d start time: %f\" %(epoch, time.time()))\n",
    "        train_loss= 0.0\n",
    "\n",
    "        for batch_idx, (data,target) in enumerate(loader):\n",
    "#x             torch.Size([batchsize, 14, 23])\n",
    "#y             torch.Size([batchsize, 3])            \n",
    "            data = data.float()\n",
    "            data= data.permute(1,0,2)\n",
    "            \n",
    "#             inputs = Variable(inputs).requires_grad_().to(device)\n",
    "            \n",
    "            target = target.float().view(-1, 3)\n",
    "\n",
    "#             print(target.shape) (3,3) -> (1,batchsize,dim)\n",
    "\n",
    "#             permute前: torch.Size([1, 7156, 23])\n",
    "#             permute後: torch.Size([7156, 1, 23])                        \n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            target = target.to(device, dtype=torch.float)\n",
    "            \n",
    "#             print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "#             print('data.shape:',data.shape)\n",
    "#             print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "#             print('target.shape:',target.shape)\n",
    "#             print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = net(data)\n",
    "            #print (output1)\n",
    "            #print (output2)\n",
    "\n",
    "            #print (output1.shape)\n",
    "            #print (output2.shape)\n",
    "\n",
    "            #total_loss= criterion_onset(output1, torch.narrow(target, dim= 2, start= 0, length= 2))\n",
    "            #total_loss = criterion_pitch(output2, torch.narrow(target, dim= 2, start= 2, length= 1))\n",
    "            total_loss = criterion_pitch(output2, target[:,2].unsqueeze(1))\n",
    "            train_loss = train_loss+ total_loss.item()\n",
    "            total_length = total_length+data.shape[1]\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "#             if batch_idx % 50 == 0:\n",
    "#                 print (\"epoch %d, sample %d, loss %.6f\" %(epoch, batch_idx, total_loss))\n",
    "#                 #print (\"current time: %f\" %(time.time()))\n",
    "#                 sys.stdin.flush()\n",
    "            \n",
    "            \n",
    "        training_loss.append(train_loss/ total_length)\n",
    "        print('epoch %d, avg loss: %.6f' %(epoch, train_loss/ total_length))\n",
    "        \n",
    "        if epoch==49:\n",
    "            model_path= f'att_ST_{epoch}.pt'\n",
    "            torch.save(net.state_dict(), model_path)  \n",
    "\n",
    "    return net\n",
    "\n",
    "def preprocess(data_seq, label):\n",
    "    new_label= []\n",
    "    for i in range(len(label)):\n",
    "        label_of_one_song= []\n",
    "        cur_note= 0\n",
    "        cur_note_onset= label[i][cur_note][0]\n",
    "        cur_note_offset= label[i][cur_note][1]\n",
    "        cur_note_pitch= label[i][cur_note][2]\n",
    "\n",
    "        for j in range(len(data_seq[i])):\n",
    "            cur_time= j* 0.032+ 0.016\n",
    "        \n",
    "            if abs(cur_time - cur_note_onset) < 0.017:\n",
    "                label_of_one_song.append(np.array([1, 0, cur_note_pitch]))\n",
    "\n",
    "            elif cur_time < cur_note_onset or cur_note >= len(label[i]):\n",
    "                label_of_one_song.append(np.array([0, 0, 0.0]))\n",
    "\n",
    "            elif abs(cur_time - cur_note_offset) < 0.017:\n",
    "                label_of_one_song.append(np.array([0, 1, cur_note_pitch]))\n",
    "                cur_note= cur_note+ 1\n",
    "                if cur_note < len(label[i]):\n",
    "                    cur_note_onset= label[i][cur_note][0]\n",
    "                    cur_note_offset= label[i][cur_note][1]\n",
    "                    cur_note_pitch= label[i][cur_note][2]\n",
    "            else:\n",
    "                label_of_one_song.append(np.array([0, 0, cur_note_pitch]))\n",
    "\n",
    "        new_label.append(label_of_one_song)\n",
    "\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------跑過一次後就可全部註解掉\n",
    "# THE_FOLDER = \"./MIR-ST500\"\n",
    "\n",
    "# data_seq= []\n",
    "# label= []\n",
    "# index = []\n",
    "# for the_dir in os.listdir(THE_FOLDER):\n",
    "#     index.append(int(the_dir))\n",
    "#     if not os.path.isdir(THE_FOLDER + \"/\" + the_dir):\n",
    "#         continue\n",
    "\n",
    "#     json_path = THE_FOLDER + \"/\" + the_dir+ f\"/{the_dir}_feature.json\"\n",
    "#     gt_path= THE_FOLDER+ \"/\" +the_dir+ \"/\"+ the_dir+ \"_groundtruth.txt\"\n",
    "\n",
    "#     youtube_link_path= THE_FOLDER+ \"/\" + the_dir+ \"/\"+ the_dir+ \"_link.txt\"\n",
    "\n",
    "#     with open(json_path, 'r') as json_file:\n",
    "#         temp = json.loads(json_file.read())\n",
    "\n",
    "#     gtdata = np.loadtxt(gt_path)\n",
    "\n",
    "#     data= []\n",
    "#     for key, value in temp.items():\n",
    "#         data.append(value)\n",
    "\n",
    "#     data= np.array(data).T #7796*23\n",
    "\n",
    "#     data_seq.append(data)\n",
    "#     label.append(gtdata)\n",
    "\n",
    "# label= preprocess(data_seq, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "THE_FOLDER = \"./MIR-ST500\"\n",
    "data_seq= []\n",
    "label= []\n",
    "\n",
    "for i in np.arange(1, 501):\n",
    "    json_path = THE_FOLDER + \"/\" + str(i) + '/' + str(i) + '_feature.json'\n",
    "    gt_path = THE_FOLDER + \"/\" + str(i) + '/' + str(i) + '_groundtruth.txt'\n",
    "    \n",
    "    with open(json_path, 'r') as json_file:\n",
    "        temp = json.loads(json_file.read())\n",
    "\n",
    "    gtdata = np.loadtxt(gt_path)\n",
    "\n",
    "    data= []\n",
    "    for key, value in temp.items():\n",
    "        data.append(value)\n",
    "\n",
    "    data= np.array(data).T #7796*23\n",
    "\n",
    "    data_seq.append(data)\n",
    "    label.append(gtdata)\n",
    "    \n",
    "label= preprocess(data_seq, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------開始切割成我們要的樣子---------------------------------\n",
    "\n",
    "##### 可調參數 L:時間長度，num_of_songs是怕data太多，500首歌\n",
    "L = 14\n",
    "num_of_songs = 450\n",
    "####\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for j in range(num_of_songs):\n",
    "    nowx = data_seq[j]\n",
    "    nowy = np.array(label[j])\n",
    "    for i in range(0,(len(nowx)-L)):\n",
    "        x = nowx[i:(i+L)]\n",
    "        xs.append(x)\n",
    "        #print(x) #總共L個\n",
    "        y = nowy[i+L]\n",
    "        ys.append(y)\n",
    "\n",
    "xs = np.stack(xs)\n",
    "xs = torch.from_numpy(xs)\n",
    "ys = np.array(ys) #(38464, 3)\n",
    "ys = torch.from_numpy(ys.astype(np.int32))        \n",
    "\n",
    "train_data = MyData(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda:4 now!\n",
      "epoch 0 start time: 1592301461.032362\n",
      "epoch 0, avg loss: 0.056221\n",
      "epoch 1 start time: 1592301681.202406\n",
      "epoch 1, avg loss: 0.053099\n",
      "epoch 2 start time: 1592301920.197719\n",
      "epoch 2, avg loss: 0.052599\n",
      "epoch 3 start time: 1592302146.800921\n",
      "epoch 3, avg loss: 0.052293\n",
      "epoch 4 start time: 1592302372.944496\n",
      "epoch 4, avg loss: 0.051906\n",
      "epoch 5 start time: 1592302597.608727\n",
      "epoch 5, avg loss: 0.051930\n",
      "epoch 6 start time: 1592302827.438080\n",
      "epoch 6, avg loss: 0.051615\n",
      "epoch 7 start time: 1592303058.259145\n",
      "epoch 7, avg loss: 0.051572\n",
      "epoch 8 start time: 1592303283.983417\n",
      "epoch 8, avg loss: 0.051437\n",
      "epoch 9 start time: 1592303510.956627\n",
      "epoch 9, avg loss: 0.051641\n",
      "epoch 10 start time: 1592303736.696519\n",
      "epoch 10, avg loss: 0.051430\n",
      "epoch 11 start time: 1592303960.773017\n",
      "epoch 11, avg loss: 0.051226\n",
      "epoch 12 start time: 1592304182.805492\n",
      "epoch 12, avg loss: 0.051217\n",
      "epoch 13 start time: 1592304407.244892\n",
      "epoch 13, avg loss: 0.051318\n",
      "epoch 14 start time: 1592304635.768561\n",
      "epoch 14, avg loss: 0.051183\n",
      "epoch 15 start time: 1592304877.910013\n",
      "epoch 15, avg loss: 0.051221\n",
      "epoch 16 start time: 1592305111.800757\n",
      "epoch 16, avg loss: 0.051334\n",
      "epoch 17 start time: 1592305338.045359\n",
      "epoch 17, avg loss: 0.051597\n",
      "epoch 18 start time: 1592305565.976757\n",
      "epoch 18, avg loss: 0.051350\n",
      "epoch 19 start time: 1592305794.220096\n",
      "epoch 19, avg loss: 0.051392\n",
      "epoch 20 start time: 1592306023.440459\n",
      "epoch 20, avg loss: 0.051143\n",
      "epoch 21 start time: 1592306248.565354\n",
      "epoch 21, avg loss: 0.050942\n",
      "epoch 22 start time: 1592306476.073991\n",
      "epoch 22, avg loss: 0.051076\n",
      "epoch 23 start time: 1592306700.893399\n",
      "epoch 23, avg loss: 0.051697\n",
      "epoch 24 start time: 1592306927.564463\n",
      "epoch 24, avg loss: 0.051693\n",
      "epoch 25 start time: 1592307157.926638\n",
      "epoch 25, avg loss: 0.051399\n",
      "epoch 26 start time: 1592307385.784402\n",
      "epoch 26, avg loss: 0.051562\n",
      "epoch 27 start time: 1592307613.191830\n",
      "epoch 27, avg loss: 0.051697\n",
      "epoch 28 start time: 1592307840.206596\n",
      "epoch 28, avg loss: 0.051895\n",
      "epoch 29 start time: 1592308069.389976\n"
     ]
    }
   ],
   "source": [
    "input_dim= 23\n",
    "hidden_size= 50\n",
    "BATCH_SIZE= 128\n",
    "loader = Data.DataLoader(dataset=train_data, batch_size= BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = Myrnn(input_dim, hidden_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr= 0.001)\n",
    "\n",
    "print(\"use\",device,\"now!\")\n",
    "\n",
    "model.to(device)\n",
    "model= do_training(model, loader, optimizer, device)\n",
    "\n",
    "#for testing\n",
    "\n",
    "#model.load_state_dict(torch.load(\"ST_5.pt\"))\n",
    "#testing(model, train_data[0], device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------testing-------------\n",
    "input_dim= 23\n",
    "hidden_size= 50\n",
    "BATCH_SIZE= 128\n",
    "L = 14\n",
    "num_of_songs = 50\n",
    "\n",
    "model = Myrnn(input_dim, hidden_size)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"att_ST_49.pt\")) #\n",
    "####\n",
    "\n",
    "for j in np.arange(num_of_songs):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    nowx = data_seq[450+j]\n",
    "    nowy = np.array(label[450+j])\n",
    "    for i in range(0,(len(nowx)-L)):\n",
    "        x = nowx[i:(i+L)]\n",
    "        xs.append(x)\n",
    "        #print(x) #總共L個\n",
    "        y = nowy[i+L]\n",
    "        ys.append(y)\n",
    "\n",
    "    xs = np.stack(xs)\n",
    "    xs = torch.from_numpy(xs)\n",
    "    ys = np.array(ys) #[14::,3]\n",
    "    ys = torch.from_numpy(ys.astype(np.int32))   \n",
    "    model.eval()\n",
    "    xs = xs.float()\n",
    "    xs= xs.permute(1,0,2)\n",
    "    ys = ys.float().view(-1, 3)\n",
    "    xs = xs.to(device, dtype=torch.float)\n",
    "    ys = ys.to(device, dtype=torch.float)\n",
    "    \n",
    "    _, output2 = model(xs)\n",
    "    pred = output2.cpu().detach().numpy()\n",
    "    true = ys[:,2].unsqueeze(1).cpu().detach().numpy()\n",
    "    data_pred = pd.DataFrame(np.hstack((pred, true)))\n",
    "    data_pred.columns = ['pred', 'true']\n",
    "    data_pred.to_csv('pitch_pred_attn/song'+str(450+j+1)+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390778, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = 0\n",
    "data1 = pd.read_csv('pitch_pred_attn/song'+str(450+1)+'.csv')\n",
    "for j in range(49):\n",
    "    data2 = pd.read_csv('pitch_pred_attn/song'+str(451+j+1)+'.csv')\n",
    "    data1 = pd.concat([data1, data2], axis=0)\n",
    "data1.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060632891309132\n"
     ]
    }
   ],
   "source": [
    "true = 0\n",
    "data1 = np.array(data1)\n",
    "for i in range(data1.shape[0]):\n",
    "    if abs(data1[i,0]-data1[i,1])<=0.5:\n",
    "        true += 1\n",
    "print(true/data1.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
